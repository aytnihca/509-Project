{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLxvLTQtAktPEJBVcmXhJ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aytnihca/509-Project/blob/main/Achintya_Raya_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "3lTHKDmyluRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "!pip install py_vollib_vectorized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1rbUcgKxJEZ",
        "outputId": "b4265b5f-4f1f-4fe5-fec9-3a9b55ebb530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py_vollib_vectorized in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: py-vollib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (0.58.1)\n",
            "Requirement already satisfied: py-lets-be-rational in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from py_vollib_vectorized) (1.11.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->py_vollib_vectorized) (0.41.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from py-vollib>=1.0.1->py_vollib_vectorized) (3.19.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->py_vollib_vectorized) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->py_vollib_vectorized) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->py_vollib_vectorized) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->py_vollib_vectorized) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part a)\n",
        "def GeoBMPaths2(S0, nu, sigma, T, Nsteps, Npaths, seed=None):\n",
        "    s = sigma * (T / Nsteps) ** .5\n",
        "    n = nu * T / Nsteps\n",
        "    increments = np.zeros((Nsteps+1, Npaths))\n",
        "    increments[0] = S0\n",
        "    rng = np.random.default_rng(seed)\n",
        "    increments[1:] = np.exp(n + rng.normal(scale=s, size=(Nsteps,Npaths)))\n",
        "    Ssample = np.cumprod(increments, axis=0)\n",
        "    return Ssample\n",
        "\n",
        "def Q1a(S0,sigma,rho,K,T1,T2,Nsteps,Npaths,seed=None):\n",
        "    paths = GeoBMPaths2(S0, rho-sigma**2/2, sigma, T2, Nsteps, Npaths, seed=12345)\n",
        "\n",
        "    k = int(np.ceil(T1*Nsteps/T2))\n",
        "    t_k = T2*k/Nsteps\n",
        "    t_k_1 = T2*(k-1)/Nsteps\n",
        "    S_t_k = paths[k,:]\n",
        "    S_t_k_1 = paths[k-1,:]\n",
        "    S_T1 = (T1 - t_k_1)/(t_k - t_k_1)*S_t_k + (t_k - T1)/(t_k - t_k_1)*S_t_k_1\n",
        "\n",
        "    integral = (S_T1+S_t_k)*(t_k - T1)/2\n",
        "    for j in range(k+1, Nsteps+1):\n",
        "      S_t_j = paths[j,:]\n",
        "      S_t_j_1 = paths[j-1,:]\n",
        "      t_j = T2*j/Nsteps\n",
        "      t_j_1 = T2*(j-1)/Nsteps\n",
        "      integral+= (S_t_j + S_t_j_1)*(t_j - t_j_1)/2\n",
        "\n",
        "    disc_payoff = np.exp(-rho * T2) * np.maximum(integral/(T2-T1) - K,0)\n",
        "    price =  disc_payoff.mean()\n",
        "    CI = stats.norm.interval(.95, loc=price, scale=stats.sem(disc_payoff))\n",
        "    return price, CI"
      ],
      "metadata": {
        "id": "UvfOajMzlyfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part b)\n",
        "from py_vollib_vectorized.implied_volatility import vectorized_implied_volatility\n",
        "sigma = vectorized_implied_volatility(593.05, 16219.94, 16700, 3.5/12, 0.01, model='black_scholes', flag = 'c')['IV']\n",
        "print('The implied volatility of the index is: ', sigma[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWraVm8QwO4h",
        "outputId": "77513ac3-848c-4c83-a84c-2c0444f05814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The implied volatility of the index is:  0.22326640281046714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part c)\n",
        "price, CI = Q1a(16219.94,sigma[0], 0.01,17000,1/12,4/12, 10000, 1000,seed=None)\n",
        "print('The price of the asian call option is: ', price)\n",
        "print('The 95% confidence interval is: ', CI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC8nNA8FyeED",
        "outputId": "1f694566-604b-4261-be44-8c1a1d3089dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of the asian call option is:  299.82002029816374\n",
            "The 95% confidence interval is:  (259.3679616753818, 340.27207892094566)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part d) No, it does not. If the option price falls outside the confidence intervals, it just means that we are in a situation that was unlikely to occur. This is obviously different from risk-free gain beyond the interest rate."
      ],
      "metadata": {
        "id": "x3Etl5O_BpoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part e)\n",
        "def Antithetic_GeoBMPaths2(S0, nu, sigma, T, Nsteps, Npaths, seed=None):\n",
        "    s = sigma * (T / Nsteps) ** .5\n",
        "    n = nu * T / Nsteps\n",
        "    increments_1 = np.zeros((Nsteps+1, Npaths))\n",
        "    increments_1[0] = S0\n",
        "    increments_2 = increments_1.copy()\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    sample1 = rng.normal(scale=s, size=(Nsteps,Npaths))\n",
        "    sample2 = rng.normal(scale=s, size=(Nsteps,Npaths))\n",
        "\n",
        "    increments_1[1:] = np.exp(n + sample1)\n",
        "    increments_2[1:] = np.exp(n - sample2)\n",
        "\n",
        "    Ssample1 = np.cumprod(increments_1, axis=0)\n",
        "    Ssample2 = np.cumprod(increments_2, axis=0)\n",
        "    return Ssample1, Ssample2\n",
        "\n",
        "def Q1e(S0,sigma,rho,K,T1,T2,Nsteps,Npaths,seed=None):\n",
        "    paths_1, paths_2 = Antithetic_GeoBMPaths2(S0, rho-sigma**2/2, sigma, T2, Nsteps, Npaths, seed=12345)\n",
        "\n",
        "    k = int(np.ceil(T1*Nsteps/T2))\n",
        "    t_k = T2*k/Nsteps\n",
        "    t_k_1 = T2*(k-1)/Nsteps\n",
        "    S1_t_k = paths_1[k,:]\n",
        "    S1_t_k_1 = paths_1[k-1,:]\n",
        "    S2_t_k = paths_2[k,:]\n",
        "    S2_t_k_1 = paths_2[k-1,:]\n",
        "    S1_T1 = (T1 - t_k_1)/(t_k - t_k_1)*S1_t_k + (t_k - T1)/(t_k - t_k_1)*S1_t_k_1\n",
        "    S2_T1 = (T1 - t_k_1)/(t_k - t_k_1)*S2_t_k + (t_k - T1)/(t_k - t_k_1)*S2_t_k_1\n",
        "\n",
        "    integral_1 = (S1_T1+S1_t_k)*(t_k - T1)/2\n",
        "    integral_2 = (S2_T1+S2_t_k)*(t_k - T1)/2\n",
        "    for j in range(k+1, Nsteps+1):\n",
        "      S1_t_j = paths_1[j,:]\n",
        "      S1_t_j_1 = paths_1[j-1,:]\n",
        "      S2_t_j = paths_2[j,:]\n",
        "      S2_t_j_1 = paths_2[j-1,:]\n",
        "\n",
        "      t_j = T2*j/Nsteps\n",
        "      t_j_1 = T2*(j-1)/Nsteps\n",
        "\n",
        "      integral_1+= (S1_t_j + S1_t_j_1)*(t_j - t_j_1)/2\n",
        "      integral_2+= (S2_t_j + S2_t_j_1)*(t_j - t_j_1)/2\n",
        "\n",
        "    disc_payoff_1 = np.exp(-rho * T2) * np.maximum(integral_1/(T2-T1) - K,0)\n",
        "    disc_payoff_2 = np.exp(-rho * T2) * np.maximum(integral_2/(T2-T1) - K,0)\n",
        "    disc_payoff = (disc_payoff_1+disc_payoff_2)/2\n",
        "    price =  disc_payoff.mean()\n",
        "    CI = stats.norm.interval(.95, loc=price, scale=stats.sem(disc_payoff))\n",
        "    return price, CI\n",
        "\n",
        "price, CI = Q1e(16219.94,sigma[0], 0.01,17000,1/12,4/12, 10000, 1000,seed=None)\n",
        "print('The price of the asian call option is: ', price)\n",
        "print('The 95% confidence interval is: ', CI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hqkw2SpBrtq",
        "outputId": "c938fc54-0879-491f-e6a8-f7f8b9081891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of the asian call option is:  308.27452914801745\n",
            "The 95% confidence interval is:  (279.3384369515039, 337.210621344531)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part e) Since we are using geometric brownian motion, it is easy to generate numbers which have negative correlation. Thus, the confidence interval is guaranteed to shrink. Antithetic sampling is guaranteed to reduce the variance by a factor 2. Therefore, the length of the confidence interval, which scales with the standard deviation, is reduced by $\\sqrt{2}$ which is what we observe as well.\n",
        "  "
      ],
      "metadata": {
        "id": "3URmHAgXMXS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "C_FSZmjeIs8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part a)\n",
        "def Q2a(alpha,beta,gamma,rho0,T,Nsteps,Npaths,seed=None):\n",
        "    dt = T/Nsteps\n",
        "    sqrt_dt = np.sqrt(dt)\n",
        "\n",
        "    paths = np.zeros((Nsteps+1, Npaths))\n",
        "    paths[0, :] = rho0\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    for i in range(1, Nsteps + 1):\n",
        "        dW = rng.normal(scale=sqrt_dt, size=Npaths)\n",
        "        paths[i,:] = paths[i-1,:] + alpha*(beta - paths[i-1,:])*dt + gamma*np.sqrt(np.maximum(paths[i-1,:],0))*dW\n",
        "    return paths"
      ],
      "metadata": {
        "id": "upHBAHoAIw9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part b)\n",
        "\n",
        "def Q2b(alpha,beta,gamma,rho0,T,Nsteps,Npaths,seed=None):\n",
        "    paths = Q2a(alpha,beta,gamma,rho0,T,Nsteps,Npaths,seed=12345)\n",
        "    T1=0; T2=T\n",
        "    # Nearly copied the code from Q1a\n",
        "    k = int(np.ceil(T1*Nsteps/T2))\n",
        "    t_k = T2*k/Nsteps\n",
        "    t_k_1 = T2*(k-1)/Nsteps\n",
        "    S_t_k = paths[k,:]\n",
        "    S_t_k_1 = paths[k-1,:]\n",
        "    S_T1 = (T1 - t_k_1)/(t_k - t_k_1)*S_t_k + (t_k - T1)/(t_k - t_k_1)*S_t_k_1\n",
        "\n",
        "    integral = (S_T1+S_t_k)*(t_k - T1)/2\n",
        "    for j in range(k+1, Nsteps+1):\n",
        "      S_t_j = paths[j,:]\n",
        "      S_t_j_1 = paths[j-1,:]\n",
        "      t_j = T2*j/Nsteps\n",
        "      t_j_1 = T2*(j-1)/Nsteps\n",
        "      integral+= (S_t_j + S_t_j_1)*(t_j - t_j_1)/2\n",
        "\n",
        "    integral = np.exp(-1*integral)\n",
        "    price =  integral.mean()\n",
        "    CI = stats.norm.interval(.95, loc=price, scale=stats.sem(integral))\n",
        "    return price, CI"
      ],
      "metadata": {
        "id": "IV8LM3vEhZrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part c)\n",
        "import pandas as pd\n",
        "\n",
        "def Q2c(parameters):\n",
        "  daily_returns = pd.read_csv('dataQ2A4.csv', index_col=0)\n",
        "  daily_returns = daily_returns.values\n",
        "\n",
        "  T = 30; Nsteps = 120; gamma = 0; Npaths = 1; rho0 = 0.05\n",
        "  alpha, beta = parameters\n",
        "\n",
        "  difference = 0\n",
        "  for i in range(Nsteps):\n",
        "    t = ((i+1)*T)/Nsteps\n",
        "    difference= difference + (Q2a(alpha,beta,gamma,rho0,t,Nsteps,Npaths,seed=12345)[120] - daily_returns[i])**2\n",
        "  return difference"
      ],
      "metadata": {
        "id": "NPZOiCseWN3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part d)\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "initial_guess = [1, 0.02]\n",
        "minimizers = minimize(Q2c, initial_guess).x\n",
        "minimized_value = Q2c(minimizers)\n",
        "print(\"Minimizers:\", minimizers)\n",
        "print(\"Corresponding value of Q2c:\", minimized_value)\n",
        "\n",
        "\n",
        "daily_returns = pd.read_csv('dataQ2A4.csv', index_col=0)\n",
        "daily_returns = daily_returns.values\n",
        "alpha, beta = minimizers\n",
        "b = minimized_value\n",
        "c = daily_returns.mean()\n",
        "T = 30; Nsteps = 120; Npaths = 100; rho0 = 0.05\n",
        "gamma = np.sqrt(b/Nsteps/c)\n",
        "\n",
        "price, CI = Q2b(alpha,beta,gamma,0.05,30,120,100,seed=12345)\n",
        "print('The price is: ', price)\n",
        "print('The 95% confidence interval of the price is: ', CI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGqIMSiWdJz_",
        "outputId": "fb263aab-026a-4042-e5a4-982c1bb5f5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimizers: [0.4745616  0.03288872]\n",
            "Corresponding value of Q2c: [9.93538043e-05]\n",
            "The price is:  0.36016921095361054\n",
            "The 95% confidence interval of the price is:  (0.3595590757771815, 0.3607793461300396)\n"
          ]
        }
      ]
    }
  ]
}